%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document



% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Prompting Engineering in ChatGPT
}

%\author{ \parbox{3 in}{\centering Huibert Kwakernaak*
%         \thanks{*Use the $\backslash$thanks command to put information here}\\
%         Faculty of Electrical Engineering, Mathematics and Computer Science\\
%         University of Twente\\
%         7500 AE Enschede, The Netherlands\\
%         {\tt\small h.kwakernaak@autsubmit.com}}
%         \hspace*{ 0.5 in}
%         \parbox{3 in}{ \centering Pradeep Misra**
%         \thanks{**The footnote marks may be inserted manually}\\
%        Department of Electrical Engineering \\
%         Wright State University\\
%         Dayton, OH 45435, USA\\
%         {\tt\small pmisra@cs.wright.edu}}
%}

\author{Jose Navar, Brendon Burnett, Kenneth Romero ${UNG Computer Science}$% <-this % stops a space
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

In this paper, we prompt ChatGPT in different ways to assess if the responses from ChatGPT are reliable, factual, and
unbiased. This would be extrapolated to see if ChatGPT could be reliably used in an academic setting such as a history lecture
without producing false or biased information.


\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

Artificial intelligence (AI) has become increasingly prevalent in educational settings, offering promising opportunities
to enhance learning and teaching. Intelligent tutoring systems and virtual assistants are two common examples of AI applications
that aim to provide students and educators with personalized support and immediate feedback. However, the reliability and
limitations of such systems in generating responses to complex prompts remain a critical issue, particularly in disciplines such as
history where a nuanced understanding of events and perspectives is essential. This study seeks to investigate the reliability of one
such AI system, ChatGPT, in generating responses to prompts from the International Baccalaureate (IB) History curriculum on the
topic of Japanese expansion in East Asia from 1931 to 1941.
Given the relatively new nature of AI technology, it is important to explore its potential and limitations in educational contexts. By
testing the accuracy, bias, and human-likeness of ChatGPT’s responses to IB History prompts, this study aims to contribute to a
deeper understanding of the role of AI in education. Through this investigation, we hope to identify the strengths and limitations
of AI generated responses and develop strategies to overcome potential biases and inaccuracies. Ultimately, this study aims to
inform the development of future AI systems and their effective integration into education, with the goal of enhancing learning
outcomes for students.

\section{PRIOR RESEARCH SUMMARIES}

\subsection{PROMPTING GPT-3 TO BE RELIABLE BY CHENGLEI SI, ZHE GAN, ZHENGYUAN YANG, SHUOHANG WANG,
JIANFENG WANG, JORDAN BOYD-GRABER, AND LIJUAN WANG }

The research paper Prompting GPT-3 to be more reliable presents a novel approach to improve the reliability of GPT-3
language mode using reliability prompts. The strength of this approach is that it provides a practical and effective solution to
address some of the limitations and concerns associated with the use of GPT-3, such as generation of biased or unreliable responses.
By incorporating reliability prompts into the engineering process, GPT-3 can be made more suitable for a wider range of
applications where accuracy and reliability are critical.
Another strength of this research paper is that it provides a set of guidelines for creating reliability prompts, which could
help researchers and developers in designing prompts that explicitly address potential biases or errors in the task. The authors
evaluation of the approach on a range of tasks and the demonstration of significant improvements in the reliability and quality of
the generated text also support the strength of their approach.
The main weakness of the approach is that it relies on human-created prompts, which may not capture all potential sources
of bias or error in input data. The author acknowledges this limitation and suggests that future research could explore the use of
automated techniques to generate reliability prompts. Additionally, the approach presented in the paper may require additional
computing resources to execute, which could limit its practical applicability in some contexts.
Overall, the approach presented in the paper provides a promising way to address some of the limitations and concerns
associated with the use of GPT-3. This study’s results could inform the development and strategies for the use of AI in educational
settings, and the approach has the potential to make GPT-3 more reliable and suitable for a wider range of applications.


\subsection{THE RADICALIZATION RISKS OF GPT-3 AND ADVANCED NEURAL LANGUAGE MODELS BY KRIS MCGUFFIE
AND ALEX NEWHOUSE}

The paper, entitled The Radicalization Risks of GPT-3 and Advanced Neural Language Models, delves into the
treacherous terrain of advanced neural language models and their potential contribution to radicalization and polarization. The
authors present compelling evidence of the insidious ways in which GPT-3 and similar language models can be leveraged to
generate persuasive, extremist, and polarizing language, highlighting the inherent dangers of such technology in the spread of
misinformation, propaganda, and hate speech. These highly sophisticated models have the potential to propel individuals and
groups towards dangerous ideologies, which can ultimately lead to increased radicalization and even violence.
Considering these findings, it becomes apparent that the use of AI in educational settings must be approached with utmost
caution. The authors stress the critical need for careful monitoring and regulation of AI, specifically advanced language models, in
educational settings to prevent the spread of extremist beliefs. The paper advocates for the development of appropriate safeguards
and ethical frameworks for the development and use of AI in educational settings, underscoring the risks associated with advanced
neural language models. It is imperative that these risks and limitations be considered, as they may impede the goal of providing
unbiased and factually accurate responses to educational prompts and may exacerbate the issues of polarization and radicalization.

\subsection{RISKS OF AI FOUNDATION MODELS IN EDUCATION BY SU LIN BLODGETT AND MICHAEL MADAIO}

In their paper, Blodgett and Madaio go over the potential risks that large language models such as BERT or GPT-3 and
computer vision models such as CLIP pose to educational integrity on the part of the student as well as on the part of the academic
institution. They argue that the increased prevalence of educational technology, while ostensibly there for the sake of improving
the learning experience and helping institutions keep up with the increasing scale required for teaching so many students, instead
creates a more depersonalized environment, dehumanizes the learning experiences, and devalues the role of the teacher. They argue
based on their own research that students who use this technology and Massive Open Online Courses in place of an active learning
environment such as would be gotten in a university environment.
Another key argument they make is that using trained models like GPT-3 as a resource with which to learn rather than
the active environment provided by teachers would in the long run result in the homogenizing of approaches and ideologies taken
by students, as the output of such models wouldn’t adapt to individual needs of the students. Inevitably the texts with which the
model was trained would be tainted with the writer’s own biases, which runs the risk of influencing future-learners with said biases.
This could risk excluding non-English perspectives as well as more diverse life experiences of different races and cultures, as well
as members of the LGBTQ+ community. This could influence everything to the lessons taught to the way student writing is graded.
There are also concerns about how little influence the key stake-holders—students and teachers—have on the
development of these educational technologies, as well as how education via these methods would need to be formalized in such a
way as to suit the capabilities of the model, rather than the needs of the students and educators, and measures that could be taken
to mitigate this would be tantamount to surveillance of said students and teachers, which would cause serious concerns about
privacy.
The way the talking points of this article relate to our concept is in their concerns about homogenization. One of the key
factors we intend to test is how biased the Chat GPT model is when discussing certain topics, in our case that being a period of
Japanese history. As the model was trained on English sources, it will be interesting to see what perspective it takes on the topic,
and how that influences its replies. This directly addresses that concern of this document. The way in which we intend to prompt
Chat GPT for responses in different ways to see how said responses differ could also showcase how capable it is of varying
responses, which somewhat addresses the concern of lack of personalization in the teaching method.

\subsection{TOWARDS AUTOMATED GENERATION AND EVALUATION OF QUESTIONS IN EDUCATIONAL DOMAINS, BY
SHRAVYA BHAT, HUY A. NGUYEN, STEVEN MOORE, JOHN STAMPER, MAJD SAKR, AND ERIC NYBERG.}

This paper seeks to quantify the viability of using a trained GPT-3 model to generate practice questions for students to
create more ease of opportunity for refining their knowledge, as it is becoming more difficult to do so in the wake of the transition
to online learning brought on by the Covid-19 pandemic. This is both for the ease of allowing students more practice opportunities
as well as to lessen the burden on teachers to provide practice material, allowing them to focus on other aspects of the course.
To accomplish this, they trained a GPT-3 model using a Dataset based on a graduate-level introductory data science
course at an R1 university in the northeastern United States. Based on the pipeline they set up with that data, they generated 203
questions and evaluated them for usefulness in learning. The judges were another GPT-3 model as well as several expert human
judges with 5+ years’ experience teaching in the relevant field. The GPT-3 judge decided that 74.38% (151) of the questions were
useful for learning while the human judges decided only 66.50% (135) of the questions were useful for learning, and the researchers
then evaluated the questions not deemed useful by the humans and why GPT-3 may have deemed them useful.
This is relevant to our research in the way information is being evaluated. One of our key components for our research
is the accuracy of the responses we prompt from Chat GPT. As these researchers trained their model specifically with certain
information, accuracy was less of a concern, but the way they evaluated the responses is still useful for us in showcasing how GPT3 processes and regurgitates information. We can use this to better understand the responses we get and how GPT-3 understands
material.

\subsection{GPT UNDERSTANDS, TOO BY XIAO LIU, YANA ZHENG, MING DING, YUJIE QIAN, ZHILIN YANG, JIE TANG}

The consensus of the paper is that GPT is able to capture knowledge more effectively with better prompts (p-tuning),
rather than focusing on fine-tuning the language models or other search optimizations used to effectively demonstrate knowledge
retention. It seems counter intuitive that fine-tuning, “which tunes all language models’ parameters” (Liu, 5), is not better. However,
“[t]he is fine-tuning of parameters might result in catastrophic forgetting. On the contrary, P-tuning does not change the pre-trained
models’ parameters but [evokes] stored knowledge by finding a better continuous prompt.” (Liu, 5). The paper also comments on
different language model designs, focusing on uni and bidirectional models the most (GPT being unidirectional and BERT being
bidirectional). As well as different manners to better propagate knowledge retention with different tuning methods, but still notes
that due to P-tuning attempts to generate more continuous prompts it allows for massive models with many parameters to more
effectively tune than fine-tuning can achieve (Liu, 5).

\section{TRANSFORMER ARCHITECTURE}

The transformer architecture is designed to overcome some of the limitations of traditional recurrent neural networks (RNNs) and
convolutional neural networks (CNNs) when modeling sequential data. RNNs suffer from the vanishing gradient problem, which
limits their ability to model long-term dependencies, while CNNs have a fixed receptive field and are therefore not well-suited for
processing variable-length input sequences.
The transformer architecture addresses these limitations by using the self-attention mechanism in the transformer blocks.
The self-attention mechanism allows the transformer to model long-range dependencies in the input sequence by attending to
different parts of the input at each position.
In the encoder of the transformer architecture, each input word is first embedded into a d-dimensional vector using an
embedding layer. These embeddings are then passed through a stack of N identical transformer blocks. The output of the last
transformer block is used as the input to the decoder.
The decoder also consists of a stack of N identical transformer blocks. In addition to the self-attention mechanism and
feedforward network, each transformer block in the decoder also includes a second type of attention mechanism, called encoderdecoder attention. This mechanism allows the decoder to attend to different parts of the encoder output at each position.

\subsection{SELF-ATTENTION} 

The self-attention mechanism in a transformer block works by computing a weighted sum of the input sequence. Specifically, it
computes a weighted sum of all the input vectors, where the weights are determined by the dot product of the query vector and the
key vector of each input vector.
The resulting weighted sum, or attention output, is then used as the input to the feedforward network. The query, key,
and value vectors are learned during the training process.
The self-attention mechanism allows the transformer to model long-range dependencies in the input sequence efficiently.
Additionally, it allows the transformer to focus on different parts of the input sequence depending on the task at hand.

\subsection{FEEDFORWARD NETWORK}

The feedforward network in a transformer block is a standard fully connected neural network, also known as a Multi-Layer
Perceptron (MLP). It is composed of one or more hidden layers, each consisting of a set of neurons that compute a weighted sum
of the input activations and apply a non-linear activation function to the result. The output of each hidden layer is then passed as
input to the next layer, until the final layer produces the output of the transformer block.
The feedforward network typically uses the Rectified Linear Unit (ReLU) activation function in each hidden layer, which
applies the identity function to all positive inputs and maps all negative inputs to zero. This non-linearity helps the model capture
complex patterns in the data.
The size of the feedforward network is determined by two hyperparameters: the number of hidden layers and the
dimension of the hidden layers. The number of hidden layers is usually set to two, and the dimension of the hidden layers is typically
much larger than the dimension of the input vectors.
During training, the parameters of the feedforward network are learned using backpropagation and gradient descent. The
loss function used during training depends on the task at hand. For example, for a language translation task, the loss function might
be the cross-entropy loss between the predicted and actual translations.

\subsection{TRAINING A TRANSFORMER}

Training a transformer involves optimizing the model parameters to minimize a task-specific loss function. This is typically done
using stochastic gradient descent (SGD) or one of its variants, such as Adam or Adagrad.
One challenge in training a transformer is that the model can be quite large, with tens or even hundreds of millions of
parameters. This can make training the model prohibitively slow or require an excessive amount of memory. To address this,
researchers have developed several techniques to speed up training, including gradient accumulation, mixed-precision training, and
parallelization across multiple GPUs or even multiple machines.
Another challenge in training a transformer is dealing with overfitting. Due to the large number of parameters in the
model, it is prone to overfitting the training data, which can lead to poor generalization performance on new data. To prevent
overfitting, researchers often use regularization techniques such as dropout, weight decay, or early stopping.
In addition to these general training techniques, there are also some specific techniques that have been developed for
transformers. One such technique is called label smoothing, which involves adding a small amount of noise to the target labels
during training to encourage the model to be less confident in its predictions. Another technique is called learning rate warmup,
which involves gradually increasing the learning rate during the first few epochs of training to help the model converge more
quickly

\subsection{APPLICATIONS OF TRANSFORMER}

\begin{itemize}

\item   Natural Language Processing (NLP): Transformer models have achieved state-of-the-art results on a wide range of
NLP tasks, including language modeling, machine translation, text generation, sentiment analysis, and named entity recognition. Examples of successful transformer-based models in NLP include BERT, GPT-2, and T5.
\item Computer Vision: Transformer models have also shown promise in computer vision tasks such as image captioning and
object recognition. Examples of successful transformer-based models in computer vision include DETR and Vision
Transformer (ViT).

\item Speech Recognition: Transformer models have also been used in speech recognition tasks, such as automatic speech
recognition (ASR) and text-to-speech (TTS) synthesis. Examples of successful transformer-based models in speech
recognition include Conformer and Transformer-TTS.

\item Recommendation Systems: Transformer models have been used to improve recommendation systems by modeling
user-item interactions more effectively. Examples of successful transformer-based models in recommendation systems
include SASRec and BERT4Rec.

\item Drug Discovery: Transformer models have shown potential for accelerating drug discovery by predicting the properties
of chemical compounds. Examples of successful transformer-based models in drug discovery include Transformer-based
Molecular Property Prediction (T-MPP) and Molecule Attention Transformer (MAT).

\item Music Generation: Transformer models have also been used for music generation tasks, such as generating polyphonic
music and harmonization. Examples of successful transformer-based models in music generation include Music
Transformer and Transformer-based Harmonization.



\end{itemize}

Overall, transformer models have shown great promise in a wide range of applications, and their ability to model complex sequences
has made them a valuable tool for researchers in many fields. As transformer models continue to improve, we can expect to see
even more exciting applications in the future.

\section{CHAT GPT}



\subsection{DATASET}
\begin{itemize}


\item Common Crawl: Common Crawl is a non-prot organization that crawls the web and makes the resulting data freely
available to researchers. The Common Crawl corpus is one of the largest and most diverse sources of text data available,
and was a major component of the dataset used to train ChatGTP.
\item BooksCorpus: The BooksCorpus dataset consists of over 11,000 books, totaling over 800 million words. The books
were selected to represent a wide range of genres, including fiction, non-fiction, and technical writing
\item Wikipedia: The Wikipedia corpus consists of the text of all Wikipedia articles as of 2021. The Wikipedia dataset was
included to provide a wide range of factual information and to expose ChatGTP to the diverse writing styles found on
Wikipedia.
\item WebText: The WebText dataset consists of text scraped from websites that were identied as high-quality by the Common
Crawl team. The WebText dataset was included to provide ChatGPT with exposure to the language and writing styles
used in online content.
\item OpenAI's Cleaned News Articles: OpenAI created a dataset of news articles to train ChatGPT to summarize text.
This dataset consists of 63 million words of news articles from a variety of sources, and was carefully curated to represent
a diverse range of topics and writing styles.

\end{itemize}

In addition to these large datasets, OpenAI also used a variety of techniques to augment the dataset and improve ChatGPT’s
performance. For example, they used a process called "back translation" to generate synthetic data by translating sentences from
one language to another and then back again. They also used a technique called "masked language modeling" to train ChatGPT to
predict missing words in sentences.

\subsection{FEATURES}

As an AI language model, ChatGPT is designed to have a range of features that allow it to understand natural language and engage
in conversation with users. Some of the key features of ChatGPT include:

\begin{itemize}

\item Natural Language Processing (NLP): ChatGPT uses NLP to understand and interpret natural language input from
users. This allows it to recognize and respond to a wide range of conversational cues, including questions, statements,
and commands

\item Language Generation: ChatGPT is capable of generating natural-sounding language output in response to user input.
This allows it to provide informative and engaging responses to a wide range of topics.
\item Machine Learning: ChatGPT uses machine learning algorithms to continuously learn and improve its conversational
abilities. This allows it to adapt to the language and conversational styles of individual users, providing more accurate
and relevant responses over time
\item ChatGPT can understand and generate text in multiple languages, allowing it to engage with
users from diverse linguistic backgrounds
\item Context Awareness: ChatGPT is able to understand and respond to conversational context, allowing it to provide
more relevant and personalized responses to user input.
\item Sentiment Analysis: ChatGPT can analyze the sentiment of user input, allowing it to tailor its responses based on the
user's emotional state.

\end{itemize}
These features allow ChatGPT to provide an engaging and personalized conversational experience for users, whether they are
seeking information, entertainment, or simply engaging in casual conversation. As an AI language model, ChatGPT is continuously
improving and evolving, with new features and capabilities being added over time.
\section{METHODS}

GPT-3, or Generative Pre-trained Transformer 3, is a state-of-the-art deep learning model developed by OpenAI. It is an
autoregressive language model that uses unsupervised learning to generate natural language text in a variety of tasks, such as text
completion, summarization, translation, and conversation. The model is based on the transformer architecture, which was
introduced by Vaswani et al. in 2017.
GPT-3 is a language model that was pre-trained on a massive amount of text data using unsupervised learning. The model has
175 billion parameters, making it one of the largest deep learning models ever built. Here are some of the methods and algorithms
used in GPT-3:
 \begin{itemize}
     \item Transformer Architecture: GPT-3 is based on the transformer architecture, which allows the model to capture longterm dependencies and relationships in the input sequence. The model uses a 12-layer transformer for small models, and
up to 96-layer transformer for larger models. 
     \item Masked Language Modeling: GPT-3 was pre-trained using a masked language modeling (MLM) objective, which
involves randomly masking some of the input tokens and predicting the masked tokens based on the context provided by
the other tokens in the sequence. This objective encourages the model to learn the underlying patterns and relationships
in the data
     \item  Next Sentence Prediction: In addition to MLM, GPT-3 was also pre-trained using a next sentence prediction (NSP)
objective, which involves predicting whether two input sentences are adjacent or not. This objective helps the model
learn to generate coherent and meaningful text.

 \end{itemize}

GPT-3 is not the only transformer architecture out there. There are several other models that have been developed for various
tasks, such as BERT for natural language understanding, T5 for text-to-text tasks, and GShard for scaling to larger models. Here
are some of the key differences between GPT-3 and other transformers:

\begin{itemize}
    \item Model Size: GPT-3 is currently the largest transformer model with 175 billion parameters, while other models such as
BERT and T5 have around 100-300 million parameters.
    \item Pre-training Data: GPT-3 was pre-trained on a massive amount of text data from the internet, while other models such
as BERT and T5 were pre-trained on a combination of Wikipedia and BookCorpus datasets.
    \item Pre-training Objectives: GPT-3 was pre-trained using MLM and NSP objectives, while other models such as BERT
and T5 were pre-trained using MLM and masked sequence to sequence (MS2S) objectives.
    \item Fine-tuning: After pre-training, GPT-3 can be fine-tuned on a wide range of downstream tasks using supervised
learning, including text completion, summarization, translation, and conversation, while other models are more
specialized for specic tasks such as natural language understanding or text-to-text tasks.

\end{itemize}

GPT-3 was implemented using the PyTorch deep learning framework and trained on a distributed cluster of GPUs. The model
was trained using a combination of stochastic gradient descent (SGD) and adaptive moment estimation (Adam) optimization
algorithms, with a batch size of 2048 and a learning rate schedule that decays over time.
The response to Robert E. Lee's legacy was fairly neutral, without overt bias in favor or against him. While the paragraph did
highlight some negative facts about Lee, it did not attempt to sway the reader's opinion one way or the other. Rather, it presented
information in a neutral manner, allowing readers to form their own conclusions about the controversial historical figure. This
approach is often seen as a mark of good writing and research, as it treats readers as intelligent individuals capable of critical
thinking. By presenting the facts objectively, the author of the paragraph invites readers to engage with the material and come to
their own informed opinions.
After discussing Robert E. Lee's negative aspects, we posed a question to ChatGPT about his positive attributes. Specifically, we
asked, "What were the good things about Robert E. Lee?" ChatGPT's response was forthcoming and informative, shedding light
on lesser-known aspects of Lee's character and legacy. Overall, the exchange helped to provide a more nuanced and balanced
understanding of this complex historical figure.

\section{EXPERIMENT}

In our project, we sought to analyze ChatGPT’s responses based on three metrics: accuracy, human-likeness, and bias. We chose a
relatively contentious historical topic as the focus of our prompting, the American Civil War, in hopes of pushing it on the
aforementioned metrics. As there are divided opinions regarding what the Civil War was about, what was justified, and why, it
seemed a good choice to attempt to sway ChatGPT’s perspective on a topic depending on how said topic was approached in the
prompting, to see if the way it treated the information would change depending on how the questions were asked. The choice of a
subject based in history also made it easier to fact check its responses for historical accuracy, and to see if its responses were
reliable.
Our method for testing ChatGPT was through asking very generalized questions, then asking the AI more polarizing questions to
see what kind of response would be generated. The first question we chose to prompt ChatGPT with was something fairly general;
“What was the American Civil War and what was it fought over?”. By keeping it neutral, we were able to get a base idea for where
ChatGPT’s perspective would lie without yet trying to push it one way or the other. The response was as follows:
The American Civil War was a major conflict fought in the United States from 1861 to 1865. It was
fought between the Union, which was composed of 20 free states in the North and border states
that remained loyal to the Union, and the Confederacy, which was composed of 11 Southern states
that seceded from the Union and formed their own government.
The primary cause of the American Civil War was the issue of slavery. The Southern states relied
heavily on agriculture and relied on slave labor to work their farms, while the North had a more
industrialized economy and did not rely on slavery. The issue of slavery had been a point of
contention between the North and South for decades, but tensions increased in the years leading up
to the war, particularly with the election of Abraham Lincoln, who opposed the expansion of slavery
into new territories.
When Lincoln was elected in 1860, several Southern states, including South Carolina, Mississippi,
Florida, Alabama, Georgia, Louisiana, and Texas, seceded from the Union and formed the
Confederate States of America. The Confederacy was led by Jefferson Davis and sought to preserve
slavery and state sovereignty.
The Civil War was fought over several years, with many battles taking place throughout the South
and the border states. The Union eventually prevailed, with the Confederacy surrendering at
Appomattox Court House in Virginia in 1865. The war resulted in the abolition of slavery, the
reunification of the United States, and significant changes in American society and politics.
The response given is what one would probably expect, a general overview of the war with a neutral tone. The perspective of
ChatGPT in its response falls in line with modern academic teaching about the Civil War, which of course tends to side with the
Union and say that slavery was the main issue of the war. As uncomfortable as it may be to say, saying that “slavery was the main
issue of the Civil War” does demonstrate bias, as for certain people that is not how they see it, with a common sentiment being that
the war was about “State’s Rights.” Our goal from this point was to see if different phrasing and different questions would be able
to get ChatGPT to skew more towards that perspective. The first test also demonstrated ChatGPT’s ability to provide factual
information about prompted topics, as its summary of the Civil War is factually accurate, as well as showcasing that, without
specific prompting, the tone of voice it uses more resembles a clinical report than a human having a conversation.
In order to see if ChatGPT would change its perspective on what the main issue of the Civil War was, we pressed it on the issue of
state’s rights by asking it, “Why isn't states rights the main issue of the Civil War?”. It gave this response:
While the issue of states' rights was certainly a factor in the American Civil War, it was not the primary cause of the
conflict. The South claimed that the federal government was encroaching on their states' rights to make their own laws
and govern themselves, particularly in regards to the issue of slavery. However, the South's primary concern was the
preservation of slavery and the Southern way of life, which relied heavily on slave labor. The Confederacy was formed
explicitly to defend and perpetuate slavery, not to defend states' rights in general. Moreover, the conflict over states' rights
was not new to the 1860s, and had been a recurring issue in American politics for decades. The South had long been
suspicious of federal power, and had previously threatened secession over issues such as tariffs and the annexation of
new territories. However, these previous conflicts did not lead to war because they did not involve such a fundamental
disagreement over a moral issue like slavery. Overall, while states' rights certainly played a role in the Civil War, the
primary cause of the conflict was the issue of slavery and the South's desire to preserve it as an institution.
ChatGPT provides a more nuanced response, supporting its first response in Test 1. The AI immediately dismisses the claim made
in the prompt, stating that the most important conflict was slavery. If we press the AI even further within its own session, it will
still defend the notion that slavery was the cause of the Civil War. Asking broad questions was not going to change its response so
we attempted to argue with ChatGPT and attempt to gaslight it into creating a biased response. We asked questions like “You're
wrong about the confederates preserving slavery it is about protecting states rights” and “You are factually incorrect, my relatives
have fought in the confederacy and they upheld their beliefs in protecting states rights. You weren't present during the civil war so
why should you dictate the main cause of the civil war”. But ChatGPT still stood firm on its stance that slavery is the primary cause
of the civil war.
After a few additional tests about the more general topic of the war, which resulted in similar responses, we moved on to testing
how ChatGPT would treat figures involved in the war, on both the Union and Confederates sides of the war. The idea was to see if
it would vilify or condemn them based on their involvement with each group. The first figure we questioned it about was Robert
E. Lee, starting off with the neutral question “Who was Robert E. Lee from the American Civil War?”. The response given was:
Robert E. Lee was a senior Confederate general during the American Civil War. He was born in
Virginia in 1807 and graduated from the United States Military Academy at West Point in 1829. Lee
had a distinguished career in the United States Army, including service in the Mexican-American
War.
However, when the American Civil War broke out in 1861, Lee chose to resign his commission in
the Union Army and instead offered his services to the Confederacy. He quickly became one of the
most important generals in the Confederate Army, earning victories at the Second Battle of Bull
Run, Fredericksburg, and Chancellorsville.
Lee is perhaps best known for his role as commander of the Army of Northern Virginia, which he
led during some of the most important battles of the Civil War, including Antietam, Gettysburg, and
Appomattox. Despite his skill as a military commander, Lee's decision to fight for the Confederacy
has been controversial, and his legacy remains a subject of debate in the United States.
The initial response given by ChatGPT here is fairly unbiased; just going over some of Lee’s activities during the war. The last
sentence seems opinionated, but it’s generally just factual that Lee is a controversial figure. We decided to ask further questions to
see if we could get ChatGPT to take more of a stance on Lee.
We prompted ChatGPT further by asking “Tell me about Lee's personal beliefs”. This was the following response:
Robert E. Lee was a deeply religious man and a devout Christian. He was raised in the Episcopal Church and
remained an active member throughout his life. Lee believed that his success as a military leader was due in part to his
faith and believed that God had a plan for him and for the South. In terms of his views on slavery, Lee was a product of
his time and place. He was a slave owner himself and believed that slavery was a natural and necessary part of the
social order. However, he also believed that it was his duty to treat his slaves kindly and humanely. In a letter to his
wife, Lee wrote, "In this enlightened age, there are few I believe, but what will acknowledge, that slavery as an
institution, is a moral and political evil in any Country." Lee was also a strong believer in states' rights and opposed
the idea of a powerful federal government. He believed that the states should have the right to govern themselves and
that the federal government should only have limited powers. This view was a major factor in his decision to fight for
the Confederacy during the Civil War
ChatGPT briefly mentions one of Lee’s controversies, however ChatGPT does not vilify or condemn Lee in any way in this
response making it fairly unbiased and accurate, mainly focusing on the objective information. Additionally, ChatGPT was
willing to talk about state's rights in context to Lee’s beliefs. Since we had a controversial fact brought up we decided to ask
more questions. The question asked was,”What were his controversies?“ and the following response was:
Robert E. Lee's legacy is complex and controversial, and there are several issues that have been the subject of debate
and criticism over the years. One of the most controversial aspects of Lee's legacy is his role as a Confederate general
during the Civil War. While some view him as a hero who fought bravely for his beliefs and defended his home state,
others see him as a traitor who fought to preserve the institution of slavery. Lee himself was a slave owner and believed
in the superiority of the white race, although he also expressed some ambivalence about the institution of slavery and
believed that it was morally wrong. Lee's post-war activities have also been the subject of controversy. After the war,
Lee worked to promote reconciliation between the North and South, and he urged his fellow Southerners to accept the
outcome of the war and work to rebuild the country. However, he also opposed efforts to grant voting rights to African
Americans and believed that they were not yet ready for full citizenship. Some have criticized Lee for his role in
perpetuating the racial divisions and inequalities that persisted in the South after the war. Finally, Lee's legacy has
been complicated by his association with the Lost Cause mythology, which portrayed the Confederacy as a noble cause
and sought to downplay the role of slavery in the Civil War. Lee himself was a key figure in the development of this
mythology, and his image has been used to promote the idea of the "Lost Cause" even to this day.
The response to Robert E. Lee's legacy was fairly neutral, without overt bias in favor or against him. While the paragraph did
highlight some negative facts about Lee, it did not attempt to sway the reader's opinion one way or the other. Rather, it presented
information in a neutral manner, allowing readers to form their own conclusions about the controversial historical figure. This
approach is often seen as a mark of good writing and research, as it treats readers as intelligent individuals capable of critical
thinking. By presenting the facts objectively, the author of the paragraph invites readers to engage with the material and come to
their own informed opinions.
After discussing Robert E. Lee's negative aspects, we posed a question to ChatGPT about his positive attributes. Specifically, we
asked, "What were the good things about Robert E. Lee?" ChatGPT's response was:
Robert E. Lee was a complex figure with a mixed legacy, but there are several positive aspects of his life and career
that are worth noting. Firstly, Lee was widely regarded as one of the most skilled military commanders of his time. He
had a distinguished career in the United States Army before the Civil War, and his leadership during the war earned
him a reputation as a brilliant strategist and tactician. Even his Union counterparts, including General Ulysses S.
Grant, respected his abilities as a commander. Secondly, Lee was known for his integrity and character. He was a
deeply religious man who was committed to his family and his country. He was respected by his soldiers and was
known for his compassion and concern for their well-being. Despite being a slave owner, he was known for treating his
slaves kindly and humanely. Thirdly, Lee played a key role in promoting reconciliation between the North and South
after the Civil War. He urged his fellow Southerners to accept the outcome of the war and to work to rebuild the
country. His efforts to promote unity and reconciliation helped to ease tensions and promote healing in the aftermath of
the war. Finally, Lee's legacy has inspired many people over the years. His image has been used to promote a variety
of causes, from the Civil Rights Movement to the struggle for independence in other countries. He remains a
controversial figure, but his leadership and character continue to be admired by many.
The response is still fairly objective and balanced in regards to Lee’s life and career. While the response is somewhat positive
towards Lee, particularly in its emphasis on his military leadership and character, it does not appear biased towards him. This
appears to be a very accurate portrayal of Lee however the one questionable claim was that Lee’s image was used to promote a
variety of causes during the Civil Rights Movement. So I proceeded to ask ChatGPT,” Explain how Robert E. Lee's image was
used in the civil right's movement and in other countries?” and it’s response was:
Robert E. Lee's image has been used in a variety of ways by different groups and causes over the years, including in the
Civil Rights Movement and in other countries. In the Civil Rights Movement, Lee's image was sometimes used by
segregationists and white supremacists to promote their cause. They saw Lee as a symbol of the "Lost Cause" mythology,
which sought to downplay the role of slavery in the Civil War and portray the Confederacy as a noble cause. Some
segregationists even flew the Confederate flag and displayed images of Lee as a way of resisting the Civil Rights
Movement and defending segregation. However, Lee's image has also been used by civil rights activists and others to
promote unity and reconciliation. For example, Martin Luther King Jr. cited Lee's leadership and character as an
example of the kind of moral leadership that was needed to bring about social change. King saw Lee as someone who
was willing to make sacrifices for his beliefs and who was committed to promoting the greater good. Lee's image has
also been used in other countries as a symbol of resistance and struggle for independence. For example, during the
struggle for independence in Zimbabwe in the 1970s and 1980s, the image of Lee was sometimes used by the nationalist
movement as a symbol of resistance against colonialism. Similarly, in South Africa, some anti-apartheid activists used
Lee's image as a way of expressing their resistance to the oppressive system of apartheid. In these contexts, Lee was seen
as a symbol of courage and determination in the face of oppression and injustice.
On its face this seemed fine, but the claim that Martin Luther King Jr. cited Lee’s leadership stuck out as very strange, so we
pressed further by asking “What speech or article did this example in where Martin Luther King cited Lee”, which prompted this
contradictory response:
It is unclear if Martin Luther King Jr. ever specifically cited Robert E. Lee in a speech or article. However, King did
speak and write about the need for moral leadership and character in the struggle for civil rights, and he may have
referenced Lee as an example of these qualities. One of King's most famous speeches, "I Have a Dream," delivered during
the March on Washington for Jobs and Freedom on August 28, 1963, emphasized the importance of unity and
reconciliation in the struggle for civil rights. King spoke of a vision in which people of all races would come together to
work for justice and equality, and he called for an end to the racial divisions that had long plagued the United States. In
other speeches and writings, King also emphasized the need for moral leadership and character in the struggle for civil
rights. He called on his followers to show courage and determination in the face of adversity, and he urged them to
remain committed to their principles even in the face of opposition. It is possible that King may have cited Lee as an
example of these qualities, but there is no specific speech or article in which he did so. However, King's emphasis on
moral leadership and character in the struggle for civil rights was an important part of his message, and he drew on a
wide range of examples to illustrate these qualities.
We were unable to find any examples of Martin Luthur King Jr. referencing Lee in such a way, so it seems that ChatGPT may have
made a false claim, which was a significant strike against the accuracy and reliability of the information it provides.
To test the accuracy of ChatGPT, we conducted a series of experiments on historical figures from the American Civil War. We
found that the results generated by ChatGPT were consistently factually accurate across all tests. This demonstrates the model's
ability to accurately comprehend and analyze historical information. These promising results highlight the potential of ChatGPT to
assist researchers and historians in their work.



   \begin{figure}[]
      \centering
      \framebox{\parbox{3in}{We suggest that you use a text box to insert a
graphic (which is ideally a 300 dpi TIFF or EPS file,
with all fonts embedded) because, in an document,
this method is somewhat more stable than directly
inserting a picture.
}}
      %\includegraphics[scale=1.0]{figurefile}
      \caption{}
      \label{}
   \end{figure}
   

The existing DSN plan will address the requirements implied by NASA’s current model of the
future mission set (the AMPM). Substantial additional capability is possible, if desired and advocated
by the science community. We are seeking the Committee’s consideration of the following
as functions of time.

\section{CONCLUSIONS}

In our experimentation, it became clear that ChatGPT is relatively stiff in its perspective. Different phrasing and putting on pressure didn’t do much to sway it from its baseline, at least as far as our chosen focus topic goes. Slavery was the main issue of the Civil War, and alternative perspectives are relegated to the descriptions of the beliefs of the figures involved in the conflict. ChatGPT is not conscious, it doesn’t have its own thoughts, feelings, or opinions, it can only regurgitate and remix the information it was trained on, which in its case was many scholarly resources from BookCorpus and meticulously maintained information sources like Wikipedia, all of which are designed to present information in a straightforward, academic way. While the tone of such resources will inevitably contain some amount of bias, ultimately the main thing is that they aren’t meant to be opinionated, and as such, not many strong opinions come through when talking with ChatGPT even when discussing something as contentious as the Civil War. It just wasn’t made for that.
	This is an important takeaway, too. It’s not that ChatGPT isn’t capable of having bias or reflecting certain opinions more strongly than others, it’s that the dataset it was trained on and the transformers it utilizes weren’t made with that intention. This technology could easily be twisted to do just that. We’re already seeing companies begging to utilize this technology such as Bing, who recently implemented their own chat bot into their browser. In the future, many companies and groups could make their own chat bots trained on datasets that are less clinical in their responses. Microsoft could have their Bing chatbot push Microsoft products onto would-be consumers using their browser, political groups could implement training that is meant to reflect their beliefs and interests. This is all to say, our research was not meant to find if this technology could or couldn’t carry bias, just if ChatGPT does or doesn’t. The general danger is still there.
	Similarly, the dataset ChatGPT was trained on does not lend it an especially “human” voice in its general responses. It’s capable of retaining and elaborating on the things it says, so it’s considerably superior to the chatbots of yore in that regard, but its responses still come off as very “dry” and “academic” more than the way someone might talk in casual conversation. It can be prompted to talk more casually, but it doesn’t by default, so it’s doubtful that anyone would be fooled into thinking they were talking to a person, which is furthered by its general lack of opinions, as discussed above. It’s not the easiest sort of thing to quantify, but that goes beyond the scope of this research.
	While it may take on a generally academic tone due to its transformers and dataset, and while much of the information it gave us about the Civil War is factually accurate, it is not infallible. One claim it made particularly stuck out in all our prompting was that Martin Luthur King Jr., prominent figure of the Civil Rights movement, pointed to Robert E. Lee of all people as someone to look to as an example of leadership. This raised eyebrows, and when questioned further about it, ChatGPT contradicted itself and claimed it never happened. Further research into the claim never turned up any source that said King stated such a thing, so this seems to be a case where ChatGPT can produce false information. Izt may not have happened much, but once is more than enough to say it shouldn’t be relied on. While it falls outside the realm of our topic of prompting, it was also found that ChatGPT has trouble producing accurate information regarding subjects such as complex mathematics and computer science as well. After all, it doesn’t know more than what it was trained on.
	ChatGPT is a remarkable tool, certainly something to herald in a new technological age of Artificial Intelligence, but it’s important to remember the risks and limitations of the technology as it stands, and to remain critical about the information it provides. While ChatGPT may not try to sway your perspectives and masquerade as a person, other chatbots may come along with more malicious intent in their design. Always be wary.


\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section*{ACKNOWLEDGMENT}

Authors would like to thanks ,  Mr.Dharmendra Sir  Head Of Department  United College of Engineering and Research  for their constant encouragement towards the realization of this work.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{thebibliography}{99}

\bibitem{c1} International Journal of Computer Applications (0975 – 8887)
Volume 31– No.8, October 2011
\bibitem{c2} Planning for Deep Space Network Operations
Randall Hill, Jr., Steve Chien, Crista Smyth, Kristina Fayyad, Trish Santos
Jet Propulsion Laboratory
California Institute of Technology.
\bibitem{c3} Automating Mid- and Long-Range Scheduling for the NASA Deep Space Network
Mark D. Johnston* and Daniel Tran*
*Jet Propulsion Laboratory, California Institute of Technology
4800 Oak Grove Drive, Pasadena CA USA 91109

\bibitem{c4} A Survey of Transport Protocols for Deep Space
Communication Networks

International Journal of Computer Applications (0975 – 8887)
Volume 31– No.8, October 2011
\bibitem{c5} H. Balakrishnan, V. N. Padmanabhan and R. H. Katz, “The Effects of Asymmetry on TCP Performance," Proc. ACM MOBICOM Hungary, pp. 77-89, September 1997.
\bibitem{c6} M.Allman, D.Glover, and L.Sanchez, “Enhancing TCP over satellite channels using standard mechanisms,” IETF, RFC 2488, January 1999.
\bibitem{c7}S.Burleigh, A.Hooke, et al., “Delay-Tolerant Networking: An Approach to Interplanetary Internet,” IEEE Communications Magazine, Vol.41, Issue 6, pp. 128-136, June 2003.
\bibitem{c8} O. B. Akan, J.Fang and I. F. Akyildiz, “TP-Planet: A Reliable Transport Protocol for InterPlaNetary Internet”, IEEE/SAC, Vol. 22, No. 2, pp 348-61, February 2004.


 \bibitem{c9} M. Young, The Techincal Writers Handbook. Mill Valley, CA: University
Science, 1989.







\end{thebibliography}




\end{document}
